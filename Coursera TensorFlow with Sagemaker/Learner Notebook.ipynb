{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Training with TensorFlow in Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import shutil\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sagemaker\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "urls = ['http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz',\n",
    "        'http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz']\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract(data_dir, download_dir):\n",
    "    for url in urls:\n",
    "        target_file = url.split('/')[-1]\n",
    "        if target_file not in os.listdir(download_dir):\n",
    "            print('Downloading', url)\n",
    "            urllib.request.urlretrieve(url, os.path.join(download_dir, target_file))\n",
    "            tf = tarfile.open(url.split('/')[-1])\n",
    "            tf.extractall(data_dir)\n",
    "        else:\n",
    "            print('Already downloaded', url)\n",
    "\n",
    "def get_annotations(file_path, annotations={}):\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        rows = f.read().splitlines()\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        image_name, _, _, _ = row.split(' ')\n",
    "        class_name = image_name.split('_')[:-1]\n",
    "        class_name = '_'.join(class_name)\n",
    "        image_name = image_name + '.jpg'\n",
    "        \n",
    "        annotations[image_name] = 'cat' if class_name[0] != class_name[0].lower() else 'dog'\n",
    "    \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "download_and_extract('data', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = get_annotations('data/annotations/trainval.txt')\n",
    "annotations = get_annotations('data/annotations/test.txt', annotations)\n",
    "\n",
    "total_count = len(annotations.keys())\n",
    "print('Total examples', total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['cat', 'dog']\n",
    "sets = ['train', 'validation']\n",
    "root_dir = 'custom_data'\n",
    "\n",
    "if not os.path.isdir(root_dir):\n",
    "    os.mkdir(root_dir)\n",
    "    \n",
    "for set_name in sets:\n",
    "    if not os.path.isdir(os.path.join(root_dir, set_name)):\n",
    "        os.mkdir(os.path.join(root_dir, set_name))\n",
    "    for class_name in classes:\n",
    "        folder = os.path.join(root_dir, set_name, class_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the files to correct set/ class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, class_name in annotations.items():\n",
    "    target_set = 'validation' if random.randint(0, 99) < 20 else 'train'\n",
    "    target_path = os.path.join(root_dir, target_set, class_name, image)\n",
    "    shutil.copy(os.path.join('data/images/', image), target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_counts = {\n",
    "    'train': 0,\n",
    "    'validation': 0\n",
    "}\n",
    "\n",
    "for set_name in sets:\n",
    "    for class_name in classes:\n",
    "        path = os.path.join(root_dir, set_name, class_name)\n",
    "        count = len(os.listdir(path))\n",
    "        print(path, 'has', count, 'images')\n",
    "        sets_counts[set_name] += count\n",
    "\n",
    "print(sets_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Script - Putting it Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with TensorFlow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dir = 'custom_data/validation/cat/'\n",
    "cat_images = [os.path.join(cat_dir, x) for x in os.listdir(cat_dir)]\n",
    "print(cat_images[0])\n",
    "\n",
    "dog_dir = 'custom_data/validation/dog/'\n",
    "dog_images = [os.path.join(dog_dir, x) for x in os.listdir(dog_dir)]\n",
    "print(dog_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    results = pets_predictor.predict(img)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = cat_images[0]\n",
    "results = get_pred(image_path)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = int(np.squeeze(results['predictions']) > 0.5)\n",
    "print('Predicted class_id:', class_id, 'with class_name:', classes[class_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Model Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(pets_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
